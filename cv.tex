% resume.tex
% vim:set ft=tex spell:

\documentclass[10pt,letterpaper]{article}
\usepackage[letterpaper,margin=0.75in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{mdwlist}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{tgpagella}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\pagestyle{empty}
\setlength{\tabcolsep}{0em}

% indentsection style, used for sections that aren't already in lists
% that need indentation to the level of all text in the document
\newenvironment{indentsection}[1]%
{\begin{list}{}%
	{\setlength{\leftmargin}{#1}}%
	\item[]%
}
{\end{list}}

% opposite of above; bump a section back toward the left margin
\newenvironment{unindentsection}[1]%
{\begin{list}{}%
	{\setlength{\leftmargin}{-0.5#1}}%
	\item[]%
}
{\end{list}}

% format two pieces of text, one left aligned and one right aligned
\newcommand{\headerrow}[2]
{\begin{tabular*}{\linewidth}{l@{\extracolsep{\fill}}r}
	#1 &
	#2 \\
\end{tabular*}}

% make "C++" look pretty when used in text by touching up the plus signs
\newcommand{\CPP}
{C\nolinebreak[4]\hspace{-.05em}\raisebox{.22ex}{\footnotesize\bf ++}}

% and the actual content starts here
\begin{document}

\begin{center}
{\LARGE \textbf{Kumar Shridhar}}

\url{kumar-shridhar.github.io} \textbullet
\ \ \texttt{shridhar.stark@gmail.com} \textbullet
\ \ +49 176 77659867
\\
Kurt-Schumacher Strasse 16, Kaiserslautern, Germany  67663
\end{center}


\hrule
\vspace{-0.4em}
\subsection*{Experience}

\begin{itemize}
	\parskip=0.1em
	
	\item
	\headerrow
		{\textbf{\href{https://www.botsupply.ai/}{BOTSUPPLY}}}
		{\textbf{Copenhagen, Denmark}}
	\\
	\headerrow
		{\emph{Chief AI Scientist}}
		{\emph{12/2016 -- Present}}
	\begin{itemize*}
		\item Developed a Natural Language Processing Framework \footnote{\url{https://www.botsupply.ai/natural-language-processing}} from scratch in 40+ languages   that powers all the customers chatbots at BotSupply\footnote{\url{https://www.botsupply.ai/}}.
		\item Created and trained models for Intent classification, Entity recognition, Sentiment Analysis, Language Translation, POS tagging that are in par with state-of-the-art models.  
		\item Designed architectures for handling imbalanced datasets, for improving performance with continuous learning over feedback and for automated selection of the  best threshold. 
		\item Gathered data and feedbacks from real users, crowd-sourced annotations, worked with linguists and designers  to improve the whole conversational flow in chatbots.
		\item My current work focuses on learning representations from unsupervised datasets that generalizes well to any tasks when fine tuned upon.
	\end{itemize*}

	\item
	\headerrow
		{\textbf{\href{https://www.insiders-technologies.de/home.html}{INSIDERS TECHNOLOGIES}}}
		{\textbf{Kaiserslautern, Germany}}
	\\
	\headerrow
		{\emph{Research Assistant}}
		{\emph{01/2018 -- 09/2018}}
	\begin{itemize*}	
		\item Worked in the Ovation Machine Learning Team of Insiders that handles huge amounts of data, reads and understands their content, handles queries or interacts with end users through Conversational Intelligent Bots.
		\item My work involved finding the most suitable and accurate model based on the client dataset and to improve the model performance on scarce datasets. 
<<<<<<< HEAD
		\item Contributed to Ovation Framework for Conversational Intelligence \footnote{\url{https://github.com/mindgarage/Ovation}} in collaboration with Mindgarage and participated in Ovation Summer Academy 2017.
=======
		\item Project was awarded Digital Thought Leadership award in leading contest of German insurance industry by leading German newspaper \emph{Süddeutsche Zeitung} and Google\footnote{\url{https://www.sv-veranstaltungen.de/site/fachbereiche/versicherungs-leuchtturm}} and covered by \emph{Süddeutsche Zeitung}\footnote{\url{http://www.sueddeutsche.de/wirtschaft/kuenstliche-intelligenz-aerger-fuer-watson-1.2772927}}.
>>>>>>> 17305ec7b3781947ba7f1cde0e3096ffc831c48e
	\end{itemize*}

	\item
	\headerrow
		{\textbf{\href{http://mindgarage.ai/}{MINDGARAGE}}}
		{\textbf{Kaiserslautern, Germany}}
	\\
	\headerrow
		{\emph{Researcher}}
		{\emph{2016 -- Present}}
	\begin{itemize*}
		\item Collaborating and researching on various deep learning algorithms like Bayesian Neural Networks, Memory and Attention models and Object detection.
		\item Assisting in various organizational activities at Mindgarage including, but not limited to: Assisting students' projects and thesis, organizing hackathons and research colloquiums, website and page maintenance, and so on.
		\item Assisted in organizing the coursework and assignments for \emph{Very Deep Learning} lectures at TU Kaiserslautern under Prof. Marcus Liwicki. 
	\end{itemize*}

\end{itemize}

\hrule
\vspace{-0.4em}
\subsection*{Education}

\begin{itemize}
	\parskip=0.1em
	
	\item 
	\headerrow
		{\textbf{University of Kaiserslautern}}
		{\textbf{Kaiserslautern, Germany}}
	\\
	\headerrow
		{\emph{Department of Computer Science, Masters}}
		{\emph{04/2016 -- Present}}
	\begin{itemize*}
		\item My coursework deals with making computers behave "intelligently": computers that understand images, speech, and texts, software that reasons, plans, and makes autonomous decisions; systems that interpret sensor data and user behavior and communicate and collaborate with users. 

        \item I got a deeper understanding in the areas of artificial intelligence, machine learning, pattern recognition, and computer vision by learning the core concepts and putting it to use in real life.
	\end{itemize*}
	
	\item 
	\headerrow
		{\textbf{Fast.ai}}
		{\textbf{International Fellowship Student}}
	\\
	\headerrow
		{\emph{Deep Learning}}
		{\emph{2017 -- 2017}}
	\begin{itemize*}
		\item I learned to apply cutting edge Deep Learning methods for Natural Language Processing, Computer Vision and Recommendation Systems to achieve state of the art results more efficiently. 

        \item The course helped a lot in understanding and experimenting with more deeply connected architectures with less computational power and to understand the underline thought behind the ideas and to further improve it. 
        The primary library used was PyTorch which provides great flexibility in experimenting with new things.
	\end{itemize*}
	
	
\end{itemize}

\hrule
\vspace{-0.4em}
\subsection*{Projects}

\begin{itemize}
	\parskip=0.1em
	
	\item 
	\headerrow
		{\textbf{University of Kaiserslautern}}
		{\textbf{Kaiserslautern, Germany}}
	\\
	\headerrow
		{\emph{Department of Computer Science, Masters}}
		{\emph{04/2016 -- Present}}
	\begin{itemize*}
		\item My coursework deals with making computers behave "intelligently": computers that understand images, speech, and texts, software that reasons, plans, and makes autonomous decisions; systems that interpret sensor data and user behavior and communicate and collaborate with users. 

        \item I got a deeper understanding in the areas of artificial intelligence, machine learning, pattern recognition, and computer vision by learning the core concepts and putting it to use in real life.
	\end{itemize*}
	
	\item 
	\headerrow
		{\textbf{Fast.ai}}
		{\textbf{International Fellowship Student}}
	\\
	\headerrow
		{\emph{Deep Learning}}
		{\emph{2017 -- 2017}}
	\begin{itemize*}
		\item I learned to apply cutting edge Deep Learning methods for Natural Language Processing, Computer Vision and Recommendation Systems to achieve state of the art results more efficiently. 

        \item The course helped a lot in understanding and experimenting with more deeply connected architectures with less computational power and to understand the underline thought behind the ideas and to further improve it. 
        The primary library used was PyTorch which provides great flexibility in experimenting with new things.
	\end{itemize*}
	
	
\end{itemize}

\hrule
\vspace{-0.4em}
\subsection*{Certificates and awards}

\begin{itemize}
	\parskip=0.1em
	
	\item 
	\headerrow
		{Google Developer Expert -- Machine Learning}
		{\emph{12/2017 -- Present}}
	\item 
	\headerrow
		{Scholarship of the Irish Research Council}
		{\emph{10/2015 -- Present}}
	\item 
	\headerrow
		{Scholarship of the \emph{Cusanuswerk}, one of the 13 German sponsorship organizations}
		{\emph{04/2014 -- 09/2015}}	
	\item 
	\headerrow
		{Microsoft Certified Professional (Programming in C\#)}
		{\emph{06/2015}}
	\item 
	\headerrow
		{Best Delegate award in various Model United Nations conferences}
		{\emph{11/2012 -- 01/2014}}
	\item 
	\headerrow
		{Second and third prizes \emph{Bundeswettbewerb Fremdsprachen}, national foreign languages competition}
		{\emph{2007 -- 2008}}
	\item 
	\headerrow
		{First and second prizes \emph{Landeswettbewerb Mathematik}, state mathematics competition}
		{\emph{2006 -- 2008}}
	

\end{itemize}

\hrule
\vspace{-0.4em}
\subsection*{Languages and Technologies}

\begin{indentsection}{\parindent}
\hyphenpenalty=1000
\begin{description*}
	\item[Programming Languages:]
	Python, Java, C\#, R, C, \LaTeX, Prolog, JavaScript, SPARQL
	\item[Technologies:]
	SciPy, NumPy, Keras, TensorFlow, DyNet, scikit-learn, NLTK, CoreNLP, MALLET, Weka, UNIX, Git
	\item[Natural Languages:]
	Fluent in German and English, advanced in French and Spanish, beginner in Portuguese and Latin	
	\item[Open Source Contributions:]
	The OpenCog Foundation
\end{description*}
\end{indentsection}

\hrule
\vspace{-0.4em}
\subsection*{Other activities}

\begin{itemize}
	\parskip=0.1em
		\item 
	\headerrow
		{\textbf{Natural Language Processing Dublin organizer}}
		{\emph{08/2016 -- Present}}
	\begin{itemize*}
		\item Organized 10 events. Meetup\footnote{\url{https://www.meetup.com/NLP-Dublin/}} has 600+ members and connects students, researchers, and industry professionals.
	\end{itemize*}

\end{itemize}

\hrule
\vspace{-0.4em}
\subsection*{Publications}

\begin{enumerate}
	\parskip=0.1em
	
	\item \textbf{Sebastian Ruder}, Barbara Plank (2018). Strong Baselines for Neural Semi-supervised Learning under Domain Shift. In \textit{Proceedings of ACL 2018}, Melbourne, Australia.

	\item Jeremy Howard*, \textbf{Sebastian Ruder}* (2018). \href{https://arxiv.org/abs/1801.06146}{Universal Language Model Fine-tuning for Text Classification}. In \textit{Proceedings of ACL 2018}, Melbourne, Australia.

	\item Anders Søgaard, \textbf{Sebastian Ruder}, Ivan Vulić (2018). \href{https://arxiv.org/abs/1805.03620}{On the Limitations of Unsupervised Bilingual Dictionary Induction}. In \textit{Proceedings of ACL 2018}, Melbourne, Australia.
	
	\item \textbf{Sebastian Ruder}, John Glover, Afshin Mehrabani, Parsa Ghaffari (2018). \href{https://arxiv.org/abs/1804.00982}{360\textdegree $\!$ $\!$ Stance Detection}. In \textit{Proceedings of NAACL-HLT 2018: System Demonstrations}, New Orleans, US. 

	\item \textbf{Sebastian Ruder}, Ivan Vulić, Anders Søgaard (2018). \href{https://arxiv.org/abs/1706.04902}{A Survey Of Cross-lingual Word Embedding Models}. \textit{Journal of Artificial Intelligence Research}.

	\item Isabelle Augenstein*, \textbf{Sebastian Ruder}*, Anders Søgaard (2018). \href{https://arxiv.org/abs/1802.09913}{Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces}. In \textit{Proceedings of NAACL-HLT 2018}, New Orleans, US. 
	
	\newenvironment{starfootnotes}
  {\par\edef\savedfootnotenumber{\number\value{footnote}}
   \renewcommand{\thefootnote}{$\star$} 
   \setcounter{footnote}{0}}
  {\par\setcounter{footnote}{\savedfootnotenumber}}
	
\begin{starfootnotes}
\footnotetext{Equal contribution.}
\end{starfootnotes}
		
	\item \textbf{Sebastian Ruder}, Barbara Plank (2017). \href{https://arxiv.org/abs/1707.05246}{Learning to select data for transfer learning with Bayesian Optimization}. In \textit{Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing}, Copenhagen, Denmark.
	
	\item \textbf{Sebastian Ruder} (2017). \href{https://arxiv.org/abs/1706.05098}{An Overview of Multi-Task Learning in Deep Neural Networks}. arXiv preprint arXiv:1706.05098.
	
	\item \textbf{Sebastian Ruder}, Joachim Bingel, Isabelle Augenstein, Anders Søgaard (2017). \href{https://arxiv.org/abs/1705.08142}{Learning what to share between loosely related tasks}. arXiv preprint arXiv:1705.08142.
	
	\item \textbf{Sebastian Ruder}, Parsa Ghaffari, John G. Breslin (2017). \href{https://arxiv.org/abs/1702.02426}{Data Selection Strategies for Multi-Domain Sentiment Analysis}. arXiv preprint arXiv:1702.02426.
	
	\item \textbf{Sebastian Ruder}, Parsa Ghaffari, John G. Breslin (2017). \href{https://arxiv.org/abs/1702.02052}{Knowledge Adaptation: Teaching to Adapt}. arXiv preprint arXiv:1702.02052.
	
	\item \textbf{Sebastian Ruder}, Parsa Ghaffari, John G. Breslin (2016). Towards a continuous modeling of natural language domains. In \textit{Proceedings of EMNLP 2016 Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods}, pages 53-57, Austin, Texas, US.
	
	\item \textbf{Sebastian Ruder}, Parsa Ghaffari, John G. Breslin (2016). A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis. In \textit{Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing}, pages 999–1005, Austin, Texas, US.
	
	\item Ian D. Wood and \textbf{Sebastian Ruder} (2016). \href{http://gsi.dit.upm.es/esa2016/Proceedings-ESA2016.pdf}{Emoji as emotion tags for tweets}. In \textit{Emotion and Sentiment Analysis Workshop, LREC}, Portorož, Slovenia.
	
	\item \textbf{Sebastian Ruder}, Peiman Barnaghi, John G. Breslin (2016). Analysis and Applications of a Novel Corpus of Influencers on Twitter. In \textit{Twitter for Research Conference}, Galway, Ireland.
	
	\item \textbf{Sebastian Ruder}, Parsa Ghaffari, John G. Breslin (2016). \href{http://www.anthology.aclweb.org/S/S16/S16-1026.pdf}{INSIGHT-1 at SemEval-2016 Task 4: Convolutional Neural Networks for Sentiment Classification and Quantification}. In \textit{Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval 2016)}, San Diego, US.
	
	\item \textbf{Sebastian Ruder}, Parsa Ghaffari, John G. Breslin (2016). \href{http://www.aclweb.org/anthology/S/S16/S16-1053.pdf}{INSIGHT-1 at SemEval-2016 Task 5: Convolutional Neural Networks for Multilingual Aspect-based Sentiment Analysis}. In \textit{Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval 2016)}, San Diego, US.
	
	\item \textbf{Sebastian Ruder} (2016). \href{https://arxiv.org/pdf/1609.04747.pdf}{An overview of gradient descent optimization algorithms}. arXiv preprint arXiv:1609.04747.

\end{enumerate}

\hrule
\vspace{-0.4em}
\subsection*{Services to the community}

\begin{itemize}
	\parskip=0.1em
	
	\item \textbf{Reviewer for journals:} Transactions on Audio, Speech and Language Processing; Artificial Intelligence; IEEE Computational Intelligence Magazine
	
	\item \textbf{Reviewer for workshops:} RELNLP 2018, DeepLo 2018, SemEval-2016 Task 5
		
	\item \textbf{Reviewer for conferences:} ACL 2018, EMNLP 2018, CoNLL 2018

\end{itemize}

\hrule
\vspace{-0.4em}
\subsection*{Talks}

\begin{itemize}
	\parskip=0.1em
	
	\item Insight@DCU Deep Learning Workshop Keynote, May 2018: Successes and Frontiers of Deep Learning\footnote{\url{https://www.slideshare.net/SebastianRuder/successes-and-frontiers-of-deep-learning}}
	
	\item Dublin Institute for Technology Computational Intelligence Course Guest Lecture, November 2017: Optimization for Deep Learning\footnote{\url{https://www.slideshare.net/SebastianRuder/optimization-for-deep-learning}}
		
	\item Natural Language Processing Copenhagen Meetup Talk, May 2017: Transfer Learning for NLP\footnote{\url{https://www.slideshare.net/SebastianRuder/transfer-learning-for-natural-language-processing}}
	
	\item Accenture Tech Talk, March 2017: Transfer Learning -- The Next Frontier for Machine Learning
	
	\item LinkedIn Tech Talk, March 2017: Transfer Learning -- The Next Frontier for Machine Learning\footnote{\url{https://www.slideshare.net/SebastianRuder/transfer-learning-the-next-frontier-for-machine-learning}}
	
	\item NLP Dublin meetup, December 2016: NIPS 2016 Highlights\footnote{\url{http://www.slideshare.net/SebastianRuder/nips-2016-highlights-sebastian-ruder}}
	
	\item INSIGHT SIG NLP meetup, August 2016: A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis\footnote{\url{http://www.slideshare.net/SebastianRuder/a-hierarchical-model-of-reviews-for-aspectbased-sentiment-analysis}}
	
	\item NLP Dublin meetup, August 2016: Softmax Approximations for Learning Word Embeddings and Language Modelling\footnote{\url{http://www.slideshare.net/SebastianRuder/softmax-approximations-for-learning-word-embeddings-and-language-modeling-sebastian-ruder}}
	
\end{itemize}

\end{document}

